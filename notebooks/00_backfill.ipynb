{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee1c599",
   "metadata": {},
   "source": [
    "# NOTEBOOK 00 ‚Äî Historical Backfill Engine (Polygon ‚Üí DuckDB)\n",
    "\n",
    "**Goal**\n",
    "\n",
    "Build the historical dataset for the Volatility Alpha Engine (VAE).\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- Pulls ~180 calendar days of daily OHLCV bars for a small ticker universe from Polygon.\n",
    "- Computes simple realized-volatility stats per ticker.\n",
    "- Writes everything into a single DuckDB file so the rest of the project has a clean, reproducible data source.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Gives the whole project **real market history**, not toy CSVs.\n",
    "- Centralizes all raw data in **DuckDB**, so every other notebook (01‚Äì06) reads from the *same* source of truth.\n",
    "- Shows a production-style pattern (API ‚Üí clean tables ‚Üí sanity checks) that‚Äôs reusable for other trading projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b6cf3",
   "metadata": {},
   "source": [
    "## 1. Imports and DuckDB connection\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Imports core Python libraries (pandas, numpy, DuckDB, plotting).\n",
    "- Adds the project root to `sys.path` so we can import from `src/polygon_client.py`.\n",
    "- Opens (or creates) our DuckDB file: `data/volatility_alpha.duckdb`.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- DuckDB is the **single source of truth** for VAE.\n",
    "- Using a DB instead of loose CSVs makes the pipeline reproducible and queryable.\n",
    "- Every later notebook (EDA, feature engineering, RL, backtests) connects to this same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caf3742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DB: /home/btheard/projects/volatility-alpha-engine/data/volatility_alpha.duckdb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- Make sure we can import from the project root ---\n",
    "PROJECT_ROOT = Path.cwd().parent  # notebooks/ -> project root\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Now this import will work\n",
    "from src.polygon_client import get_underlying_bars, compute_realized_vol\n",
    "\n",
    "# --- Use the SAME DuckDB file as notebooks 1‚Äì6 ---\n",
    "DB_PATH = (PROJECT_ROOT / \"data\" / \"volatility_alpha.duckdb\").as_posix()\n",
    "con = duckdb.connect(DB_PATH)\n",
    "\n",
    "print(\"Using DB:\", DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9aefa6",
   "metadata": {},
   "source": [
    "## 2. Choose tickers and backfill window\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Defines the small universe of tickers we care about right now  \n",
    "  (`AAPL`, `AMD`, `AMZN`, `GOOGL`, `META`, `MSFT`, `NVDA`, `QQQ`, `SPY`, `TSLA`).\n",
    "- Sets the backfill window to **180 calendar days** ending on `end_date`.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- 180 calendar days ‚âà 120 trading days ‚Äî enough history to:\n",
    "  - compute 20-day and 60-day realized volatility, and  \n",
    "  - run simple backtests and RL training without crushing the free Polygon limits.\n",
    "- Starting with a tight ticker universe keeps API usage and debug time reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a032e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2025-06-07',\n",
       " '2025-12-04',\n",
       " ['AAPL',\n",
       "  'MSFT',\n",
       "  'GOOGL',\n",
       "  'AMZN',\n",
       "  'META',\n",
       "  'NVDA',\n",
       "  'TSLA',\n",
       "  'AMD',\n",
       "  'SPY',\n",
       "  'QQQ'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\",\n",
    "    \"NVDA\", \"TSLA\", \"AMD\", \"SPY\", \"QQQ\"]\n",
    "\n",
    "end_date = datetime.now() # type: ignore\n",
    "start_date = end_date - timedelta(days=180) # type: ignore\n",
    "\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "start_date_str, end_date_str, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42e2a2",
   "metadata": {},
   "source": [
    "## 3. Download daily OHLC bars from Polygon\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Loops over each ticker and calls `get_underlying_bars()` to pull daily OHLCV data.\n",
    "- Adds a `ticker` column to each DataFrame.\n",
    "- Collects all per-ticker DataFrames in a Python list and prints a short success/fail summary.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- These daily bars (Open, High, Low, Close, Volume) are the **raw material** for everything:\n",
    "  - day-over-day returns,\n",
    "  - realized volatility (RV20, RV60),\n",
    "  - edge scores, and\n",
    "  - all backtests / RL experiments.\n",
    "- The summary at the bottom tells us immediately if any ticker failed due to rate limits or network issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948ee42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Fetching AAPL...\n",
      "‚úÖ Loaded 180 bars for AAPL (attempt 1)\n",
      "\n",
      "üîÑ Fetching MSFT...\n",
      "‚úÖ Loaded 180 bars for MSFT (attempt 1)\n",
      "\n",
      "üîÑ Fetching GOOGL...\n",
      "‚úÖ Loaded 180 bars for GOOGL (attempt 1)\n",
      "\n",
      "üîÑ Fetching AMZN...\n",
      "‚úÖ Loaded 180 bars for AMZN (attempt 1)\n",
      "\n",
      "üîÑ Fetching META...\n",
      "‚úÖ Loaded 180 bars for META (attempt 1)\n",
      "\n",
      "üîÑ Fetching NVDA...\n",
      "‚ùå Attempt 1 failed for NVDA: HTTPSConnectionPool(host='api.polygon.io', port=443): Max retries exceeded with url: /v2/aggs/ticker/NVDA/range/1/day/2024-06-12/2025-12-04?limit=540 (Caused by ResponseError('too many 429 error responses'))\n",
      "‚úÖ Loaded 180 bars for NVDA (attempt 2)\n",
      "\n",
      "üîÑ Fetching TSLA...\n",
      "‚úÖ Loaded 180 bars for TSLA (attempt 1)\n",
      "\n",
      "üîÑ Fetching AMD...\n",
      "‚úÖ Loaded 180 bars for AMD (attempt 1)\n",
      "\n",
      "üîÑ Fetching SPY...\n",
      "‚úÖ Loaded 180 bars for SPY (attempt 1)\n",
      "\n",
      "üîÑ Fetching QQQ...\n",
      "‚úÖ Loaded 180 bars for QQQ (attempt 1)\n",
      "\n",
      "======== Backfill summary ========\n",
      "Successful tickers: ['AAPL', 'AMD', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'QQQ', 'SPY', 'TSLA']\n",
      "Failed tickers: []\n"
     ]
    }
   ],
   "source": [
    "DAYS_HISTORY = 180  # how many calendar days to request from Polygon\n",
    "\n",
    "all_rows = []\n",
    "failed = []\n",
    "\n",
    "for symbol in tickers:  # type: ignore\n",
    "    print(f\"\\nüîÑ Fetching {symbol}...\")\n",
    "    \n",
    "    for attempt in range(3):   # up to 3 attempts per symbol\n",
    "        try:\n",
    "            bars = get_underlying_bars(symbol, days=DAYS_HISTORY)  # type: ignore\n",
    "\n",
    "            # If API returns nothing, don't keep retrying\n",
    "            if bars is None or bars.empty:\n",
    "                print(f\"‚ö†Ô∏è No bars for {symbol} (empty response)\")\n",
    "                break\n",
    "\n",
    "            # Tag ticker and store\n",
    "            bars = bars.copy()\n",
    "            bars[\"ticker\"] = symbol\n",
    "            all_rows.append(bars)\n",
    "\n",
    "            print(f\"‚úÖ Loaded {len(bars)} bars for {symbol} (attempt {attempt + 1})\")\n",
    "            break  # success ‚Üí stop retrying this symbol\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed for {symbol}: {e}\")\n",
    "            time.sleep(2 * (attempt + 1))  # simple backoff: 2s, 4s, 6s\n",
    "\n",
    "    else:\n",
    "        # Only hits if all 3 attempts failed\n",
    "        print(f\"üö´ Giving up on {symbol} after 3 failed attempts\")\n",
    "        failed.append(symbol)\n",
    "\n",
    "    # Small pause between symbols to be nice to Polygon / your network\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\n======== Backfill summary ========\")\n",
    "if all_rows:\n",
    "    print(\"Successful tickers:\", sorted({df_['ticker'].iloc[0] for df_ in all_rows}))\n",
    "else:\n",
    "    print(\"No successful tickers!\")\n",
    "\n",
    "print(\"Failed tickers:\", failed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bc664",
   "metadata": {},
   "source": [
    "## 4. Combine and clean the raw bar data\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Concatenates all per-ticker DataFrames into a single `df_bars`.\n",
    "- Normalizes the time column into a clean `date` column (`YYYY-MM-DD`).\n",
    "- Ensures we have the standard quant columns: `date`, `open`, `high`, `low`, `close`, `volume`, `ticker`.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Having *one* tidy table makes it easy to:\n",
    "  - compute returns and volatility,\n",
    "  - run SQL queries in DuckDB, and\n",
    "  - share this data with other notebooks.\n",
    "- Cleaning the time field up front avoids subtle bugs later when we join on date or slice time ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed43f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfill bars columns: ['open', 'high', 'low', 'close', 'volume', 'ticker']\n",
      "Backfill bars index name: timestamp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>214.22</td>\n",
       "      <td>218.7600</td>\n",
       "      <td>213.75</td>\n",
       "      <td>215.24</td>\n",
       "      <td>54385391.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>213.99</td>\n",
       "      <td>217.4899</td>\n",
       "      <td>212.22</td>\n",
       "      <td>214.10</td>\n",
       "      <td>48862947.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>211.56</td>\n",
       "      <td>218.8400</td>\n",
       "      <td>211.28</td>\n",
       "      <td>218.27</td>\n",
       "      <td>94127768.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>221.00</td>\n",
       "      <td>221.4800</td>\n",
       "      <td>218.58</td>\n",
       "      <td>220.73</td>\n",
       "      <td>44299483.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>220.77</td>\n",
       "      <td>224.1000</td>\n",
       "      <td>220.08</td>\n",
       "      <td>223.75</td>\n",
       "      <td>34493583.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open      high     low   close      volume ticker\n",
       "0  2025-03-19  214.22  218.7600  213.75  215.24  54385391.0   AAPL\n",
       "1  2025-03-20  213.99  217.4899  212.22  214.10  48862947.0   AAPL\n",
       "2  2025-03-21  211.56  218.8400  211.28  218.27  94127768.0   AAPL\n",
       "3  2025-03-24  221.00  221.4800  218.58  220.73  44299483.0   AAPL\n",
       "4  2025-03-25  220.77  224.1000  220.08  223.75  34493583.0   AAPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine and clean the raw bar data\n",
    "\n",
    "# What this cell does\n",
    "# - Concatenate all per-ticker DataFrames into a single df_bars\n",
    "# - Move Polygon‚Äôs time field (index or column) into a proper 'date' column\n",
    "# - Normalize to calendar dates (YYYY-MM-DD)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No data returned from Polygon. Check API key or rate limits.\")\n",
    "\n",
    "# 1) Combine all tickers' bars into one DataFrame WITHOUT dropping the index\n",
    "df_bars = pd.concat(all_rows)\n",
    "\n",
    "print(\"Backfill bars columns:\", list(df_bars.columns))\n",
    "print(\"Backfill bars index name:\", df_bars.index.name)\n",
    "\n",
    "cols = df_bars.columns\n",
    "\n",
    "# 2) Ensure we have a 'date' column from whatever time field Polygon gave us\n",
    "if df_bars.index.name in (\"timestamp\", \"t\"):\n",
    "    # Time is stored in the index (common with Polygon)\n",
    "    df_bars = df_bars.reset_index()\n",
    "    time_col = df_bars.columns[0]          # former index column\n",
    "    df_bars.rename(columns={time_col: \"date\"}, inplace=True)\n",
    "elif \"timestamp\" in cols:\n",
    "    df_bars[\"date\"] = df_bars[\"timestamp\"]\n",
    "elif \"t\" in cols:\n",
    "    df_bars[\"date\"] = df_bars[\"t\"]\n",
    "elif \"date\" in cols:\n",
    "    # Already have a date-like column; reuse it\n",
    "    df_bars[\"date\"] = df_bars[\"date\"]\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        f\"Expected a time column or index in bars, but got columns={list(cols)}, index={df_bars.index.name}\"\n",
    "    )\n",
    "\n",
    "# 3) Convert to proper datetime, then to calendar date\n",
    "df_bars[\"date\"] = pd.to_datetime(df_bars[\"date\"], unit=\"ms\", errors=\"coerce\")\n",
    "if df_bars[\"date\"].isna().all():\n",
    "    # Fallback if it's already datetime and unit=\"ms\" was wrong\n",
    "    df_bars[\"date\"] = pd.to_datetime(df_bars[\"date\"], errors=\"coerce\")\n",
    "\n",
    "if df_bars[\"date\"].isna().all():\n",
    "    raise RuntimeError(\"Failed to convert time field to datetime; inspect df_bars.head().\")\n",
    "\n",
    "df_bars[\"date\"] = df_bars[\"date\"].dt.date\n",
    "\n",
    "df_bars.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b389651",
   "metadata": {},
   "source": [
    "## 5. Compute 20-day and 60-day realized volatility per ticker\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "For each ticker, sorted by date:\n",
    "\n",
    "- Computes the **daily % return** from close-to-close.\n",
    "- Rolls those returns into:\n",
    "  - 20-day realized volatility (`rv_20d`),\n",
    "  - 60-day realized volatility (`rv_60d`).\n",
    "- Builds a per-ticker snapshot table `df_rv` with:\n",
    "  - `run_date` (snapshot date),\n",
    "  - `ticker`,\n",
    "  - `last_price`,\n",
    "  - `day_pct` (today‚Äôs move),\n",
    "  - `volume`,\n",
    "  - `rv_20d`, `rv_60d`,\n",
    "  - `edge_score` (a simple ‚Äútoday vs recent vol‚Äù metric).\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Realized volatility is the **heart** of VAE:\n",
    "  - drives the edge score,\n",
    "  - shapes which names look interesting,\n",
    "  - feeds directly into the RL state and reward.\n",
    "- Keeping one row per ticker per day is ideal for screening, plotting, and feeding into models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3b739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rv shape: (1200, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>last_price</th>\n",
       "      <th>day_pct</th>\n",
       "      <th>volume</th>\n",
       "      <th>rv_20d</th>\n",
       "      <th>rv_60d</th>\n",
       "      <th>edge_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>196.45</td>\n",
       "      <td>-1.380522</td>\n",
       "      <td>51447349.0</td>\n",
       "      <td>20.945016</td>\n",
       "      <td>51.249474</td>\n",
       "      <td>6.591172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>198.42</td>\n",
       "      <td>1.002800</td>\n",
       "      <td>43020691.0</td>\n",
       "      <td>21.483382</td>\n",
       "      <td>51.291068</td>\n",
       "      <td>4.667793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>195.64</td>\n",
       "      <td>-1.401068</td>\n",
       "      <td>38856152.0</td>\n",
       "      <td>21.620035</td>\n",
       "      <td>51.185641</td>\n",
       "      <td>6.480417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>196.58</td>\n",
       "      <td>0.480474</td>\n",
       "      <td>45394689.0</td>\n",
       "      <td>21.672431</td>\n",
       "      <td>51.134823</td>\n",
       "      <td>2.216984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>201.00</td>\n",
       "      <td>2.248448</td>\n",
       "      <td>96813542.0</td>\n",
       "      <td>21.957809</td>\n",
       "      <td>51.277561</td>\n",
       "      <td>10.239858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run_date ticker  last_price   day_pct      volume     rv_20d     rv_60d  \\\n",
       "60  2025-06-13   AAPL      196.45 -1.380522  51447349.0  20.945016  51.249474   \n",
       "61  2025-06-16   AAPL      198.42  1.002800  43020691.0  21.483382  51.291068   \n",
       "62  2025-06-17   AAPL      195.64 -1.401068  38856152.0  21.620035  51.185641   \n",
       "63  2025-06-18   AAPL      196.58  0.480474  45394689.0  21.672431  51.134823   \n",
       "64  2025-06-20   AAPL      201.00  2.248448  96813542.0  21.957809  51.277561   \n",
       "\n",
       "    edge_score  \n",
       "60    6.591172  \n",
       "61    4.667793  \n",
       "62    6.480417  \n",
       "63    2.216984  \n",
       "64   10.239858  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Build daily realized vol + edge score from 180-day bars ===\n",
    "\n",
    "# df_bars should already exist from the Polygon backfill:\n",
    "# columns like: ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "bars = df_bars.copy()\n",
    "bars = bars.sort_values([\"ticker\", \"date\"])\n",
    "\n",
    "# 1-day returns\n",
    "bars[\"ret\"] = bars.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "\n",
    "# Daily % move (this is what Notebook 1 calls day_pct)\n",
    "bars[\"day_pct\"] = bars[\"ret\"] * 100.0\n",
    "\n",
    "ann_factor = np.sqrt(252)\n",
    "\n",
    "# 20-day realized vol (annualized, in %)\n",
    "bars[\"rv_20d\"] = (\n",
    "    bars.groupby(\"ticker\")[\"ret\"]\n",
    "        .rolling(20)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "        * ann_factor * 100.0\n",
    ")\n",
    "\n",
    "# 60-day realized vol (annualized, in %)\n",
    "bars[\"rv_60d\"] = (\n",
    "    bars.groupby(\"ticker\")[\"ret\"]\n",
    "        .rolling(60)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "        * ann_factor * 100.0\n",
    ")\n",
    "\n",
    "# Simple ‚Äúedge‚Äù proxy: how big today‚Äôs move is vs recent vol\n",
    "bars[\"edge_score\"] = (bars[\"day_pct\"].abs() / bars[\"rv_20d\"]) * 100.0\n",
    "\n",
    "# This is the table we‚Äôll persist\n",
    "df_rv = (\n",
    "    bars[[\"date\", \"ticker\", \"close\", \"day_pct\", \"volume\",\n",
    "          \"rv_20d\", \"rv_60d\", \"edge_score\"]]\n",
    "      .rename(columns={\"date\": \"run_date\", \"close\": \"last_price\"})\n",
    "      .dropna()\n",
    ")\n",
    "\n",
    "print(\"df_rv shape:\", df_rv.shape)\n",
    "df_rv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d350d",
   "metadata": {},
   "source": [
    "## 6. Write OHLC and volatility tables to DuckDB\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Creates or replaces two canonical tables in DuckDB:\n",
    "\n",
    "  - `ohlc_bars`  ‚Äì one row per ticker per date with OHLCV data.  \n",
    "  - `daily_rv`   ‚Äì one row per ticker per date with returns, RV20, RV60, edge score.\n",
    "\n",
    "- Inserts the new data into each table.\n",
    "- Rebuilds the `screener_snapshots` table from the tail of `daily_rv`\n",
    "  so downstream notebooks can quickly query the most recent snapshot.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- From here on, **all** notebooks read from DuckDB tables, not from ad-hoc pandas objects.\n",
    "- `ohlc_bars` is the long history; `daily_rv` / `screener_snapshots` are the ‚Äúscreen today‚Äù view.\n",
    "- This looks and feels like a real quant data warehouse instead of one-off CSV dumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6225ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohlc_bars row count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows\n",
       "0    1800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_rv row count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows\n",
       "0    1200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screener_snapshots summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>2025-12-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows  n_tickers   min_date   max_date\n",
       "0    1200         10 2025-06-13 2025-12-03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Persist bars & realized-vol tables into DuckDB ===\n",
    "\n",
    "# 0) Safety: drop old versions so schemas can't conflict\n",
    "con.execute(\"DROP TABLE IF EXISTS ohlc_bars;\")\n",
    "con.execute(\"DROP TABLE IF EXISTS daily_rv;\")\n",
    "con.execute(\"DROP TABLE IF EXISTS screener_snapshots;\")\n",
    "\n",
    "# 1) OHLC bars (180 days √ó 10 tickers = 1800 rows)\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE ohlc_bars AS\n",
    "SELECT * FROM df_bars;\n",
    "\"\"\")\n",
    "\n",
    "print(\"ohlc_bars row count:\")\n",
    "display(con.execute(\"SELECT COUNT(*) AS n_rows FROM ohlc_bars;\").df())\n",
    "\n",
    "# 2) Daily realized vol + edge (df_rv from the cell above)\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE daily_rv AS\n",
    "SELECT * FROM df_rv;\n",
    "\"\"\")\n",
    "\n",
    "print(\"daily_rv row count:\")\n",
    "display(con.execute(\"SELECT COUNT(*) AS n_rows FROM daily_rv;\").df())\n",
    "\n",
    "# 3) Rebuild screener_snapshots using the expected column names\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE screener_snapshots AS\n",
    "SELECT\n",
    "    run_date,\n",
    "    ticker,\n",
    "    last_price,\n",
    "    day_pct,\n",
    "    volume,\n",
    "    rv_20d,\n",
    "    rv_60d,\n",
    "    edge_score\n",
    "FROM daily_rv\n",
    "ORDER BY run_date, ticker;\n",
    "\"\"\")\n",
    "\n",
    "print(\"screener_snapshots summary:\")\n",
    "display(con.execute(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*)               AS n_rows,\n",
    "        COUNT(DISTINCT ticker) AS n_tickers,\n",
    "        MIN(run_date)          AS min_date,\n",
    "        MAX(run_date)          AS max_date\n",
    "    FROM screener_snapshots;\n",
    "\"\"\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5b3100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>2025-12-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows  n_tickers   min_date   max_date\n",
       "0    1200         10 2025-06-13 2025-12-03"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild screener_snapshots from the full daily_rv history\n",
    "\n",
    "# 1. Drop old table (with just 2 days) if it exists\n",
    "con.execute(\"DROP TABLE IF EXISTS screener_snapshots\")\n",
    "\n",
    "# 2. Recreate screener_snapshots from daily_rv\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE screener_snapshots AS\n",
    "    SELECT\n",
    "        run_date,\n",
    "        ticker,\n",
    "        last_price,\n",
    "        day_pct,\n",
    "        volume,\n",
    "        rv_20d,\n",
    "        rv_60d,\n",
    "        edge_score\n",
    "    FROM daily_rv\n",
    "    ORDER BY run_date, ticker\n",
    "\"\"\")\n",
    "\n",
    "# 3. Sanity check: should now show 1800 rows and 180-day span\n",
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*)             AS n_rows,\n",
    "        COUNT(DISTINCT ticker) AS n_tickers,\n",
    "        MIN(run_date)        AS min_date,\n",
    "        MAX(run_date)        AS max_date\n",
    "    FROM screener_snapshots\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2d93a",
   "metadata": {},
   "source": [
    "## 7. Quick sanity checks\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Confirms the date range stored in `ohlc_bars` (min/max date).\n",
    "- Counts the number of rows per ticker.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Verifies that we actually captured the expected ~180 days of data.\n",
    "- Catches issues like:\n",
    "  - missing tickers,\n",
    "  - partial histories for one symbol,\n",
    "  - or weird gaps in the API response.\n",
    "- If anything looks off here, we fix it *before* touching EDA, features, or RL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31499d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>2025-12-03</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_date   max_date  n_rows\n",
       "0 2025-03-19 2025-12-03    1800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT \n",
    "    MIN(date) AS min_date,\n",
    "    MAX(date) AS max_date,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM ohlc_bars;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c14bb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>META</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPY</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  n_rows\n",
       "0   AAPL     180\n",
       "1    AMD     180\n",
       "2   AMZN     180\n",
       "3  GOOGL     180\n",
       "4   META     180\n",
       "5   MSFT     180\n",
       "6   NVDA     180\n",
       "7    QQQ     180\n",
       "8    SPY     180\n",
       "9   TSLA     180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT \n",
    "    ticker,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM ohlc_bars\n",
    "GROUP BY ticker\n",
    "ORDER BY ticker;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c27c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfill bars columns: ['date', 'open', 'high', 'low', 'close', 'volume', 'ticker']\n",
      "Backfill bars index name: None\n",
      "Tickers in backfill: ['AAPL', 'AMD', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'QQQ', 'SPY', 'TSLA']\n",
      "Date range in backfill: 2025-03-19 ‚Üí 2025-12-03\n",
      "Total rows: 1800\n"
     ]
    }
   ],
   "source": [
    "print(\"Backfill bars columns:\", list(df_bars.columns))\n",
    "print(\"Backfill bars index name:\", df_bars.index.name)\n",
    "print(\"Tickers in backfill:\", sorted(df_bars[\"ticker\"].unique()))\n",
    "print(\"Date range in backfill:\", df_bars[\"date\"].min(), \"‚Üí\", df_bars[\"date\"].max())\n",
    "print(\"Total rows:\", len(df_bars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672d5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b22b72",
   "metadata": {},
   "source": [
    "## 8. Wrap-up ‚Äî what this notebook proves\n",
    "\n",
    "**What we did**\n",
    "\n",
    "- Pulled ~180 days of daily OHLCV bars from Polygon for a small ticker universe.\n",
    "- Computed simple realized-volatility summaries (`rv_20d`, `rv_60d`) and an `edge_score`.\n",
    "- Stored everything in DuckDB tables:\n",
    "\n",
    "  - `ohlc_bars` ‚Äì full history  \n",
    "  - `daily_rv`  ‚Äì per-ticker volatility snapshots  \n",
    "  - `screener_snapshots` ‚Äì recent-window view for screening & RL\n",
    "\n",
    "**Why it matters for VAE and RL**\n",
    "\n",
    "- All downstream notebooks (01‚Äì06) now run on **real market history**.\n",
    "- We have a clean, reproducible research pipeline:\n",
    "  - External market data API ‚Üí tidy tables ‚Üí sanity checks ‚Üí saved to DuckDB.\n",
    "  - Easy to rerun if we want fresher data or a bigger ticker universe.\n",
    "\n",
    "**Next step**\n",
    "\n",
    "Open **Notebook 01** to explore this history (EDA) and see how volatility behaves across our universe.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
