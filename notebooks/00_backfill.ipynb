{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee1c599",
   "metadata": {},
   "source": [
    "# Notebook 00 ‚Äî Historical Backfill Engine (Polygon ‚Üí DuckDB)\n",
    "\n",
    "This notebook builds a **real historical dataset** for the Volatility Alpha Engine (VAE).\n",
    "\n",
    "We pull 60‚Äì180 days of market data from **Polygon**, compute basic volatility stats,\n",
    "and store everything in **DuckDB**. The other notebooks (01‚Äì06) and the RL system\n",
    "will read from this same DuckDB file.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Makes our project look like real quant research (not toy, single-day data).\n",
    "- Gives us enough history for EDA, features, regimes, and RL training.\n",
    "- Shows we can build a reproducible data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b6cf3",
   "metadata": {},
   "source": [
    "## 1. Imports and DuckDB connection\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Imports Python libraries we need (dates, dataframes, DuckDB).\n",
    "- Imports our Polygon helper functions from `src/polygon_client.py`.\n",
    "- Connects to the main DuckDB database file for VAE.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- DuckDB is our **single source of truth** for all notebooks.\n",
    "- Using one DB file keeps the pipeline clean and reproducible.\n",
    "- We see a real data-engineering pattern, not ad-hoc CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caf3742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DB: /home/btheard/projects/volatility-alpha-engine/data/volatility_alpha.duckdb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- Make sure we can import from the project root ---\n",
    "PROJECT_ROOT = Path.cwd().parent  # notebooks/ -> project root\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Now this import will work\n",
    "from src.polygon_client import get_underlying_bars, compute_realized_vol\n",
    "\n",
    "# --- Use the SAME DuckDB file as notebooks 1‚Äì6 ---\n",
    "DB_PATH = (PROJECT_ROOT / \"data\" / \"volatility_alpha.duckdb\").as_posix()\n",
    "con = duckdb.connect(DB_PATH)\n",
    "\n",
    "print(\"Using DB:\", DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9aefa6",
   "metadata": {},
   "source": [
    "## 2. Choose tickers and backfill window\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Defines the small universe of tickers we care about right now.\n",
    "- Sets a date window (last ~180 calendar days) to backfill.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- ~180 calendar days ‚âà 120 trading days, which is enough for:\n",
    "  - 20-day and 60-day realized volatility\n",
    "  - Stable features and RL training episodes\n",
    "- We keep the universe small at first to avoid hitting Polygon rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a032e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2025-06-06',\n",
       " '2025-12-03',\n",
       " ['AAPL',\n",
       "  'MSFT',\n",
       "  'GOOGL',\n",
       "  'AMZN',\n",
       "  'META',\n",
       "  'NVDA',\n",
       "  'TSLA',\n",
       "  'AMD',\n",
       "  'SPY',\n",
       "  'QQQ'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\",\n",
    "    \"NVDA\", \"TSLA\", \"AMD\", \"SPY\", \"QQQ\"]\n",
    "\n",
    "end_date = datetime.now() # type: ignore\n",
    "start_date = end_date - timedelta(days=180) # type: ignore\n",
    "\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "start_date_str, end_date_str, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42e2a2",
   "metadata": {},
   "source": [
    "## 3. Download daily OHLC bars from Polygon\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Loops over each ticker.\n",
    "- Calls `get_underlying_bars()` to fetch roughly 90 days of daily bars.\n",
    "- Attaches a `ticker` column and collects all rows in a list.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- OHLC (Open, High, Low, Close, Volume) is the core price data\n",
    "  used in most trading and RL systems.\n",
    "- This is our **raw market tape** that everything else builds on\n",
    "  (features, regimes, signals, RL environment).\n",
    "- We print basic status so we can see which tickers succeeded or failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948ee42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Fetching AAPL...\n",
      "‚úÖ Loaded 180 bars for AAPL (attempt 1)\n",
      "\n",
      "üîÑ Fetching MSFT...\n",
      "‚úÖ Loaded 180 bars for MSFT (attempt 1)\n",
      "\n",
      "üîÑ Fetching GOOGL...\n",
      "‚úÖ Loaded 180 bars for GOOGL (attempt 1)\n",
      "\n",
      "üîÑ Fetching AMZN...\n",
      "‚úÖ Loaded 180 bars for AMZN (attempt 1)\n",
      "\n",
      "üîÑ Fetching META...\n",
      "‚úÖ Loaded 180 bars for META (attempt 1)\n",
      "\n",
      "üîÑ Fetching NVDA...\n",
      "‚úÖ Loaded 180 bars for NVDA (attempt 1)\n",
      "\n",
      "üîÑ Fetching TSLA...\n",
      "‚úÖ Loaded 180 bars for TSLA (attempt 1)\n",
      "\n",
      "üîÑ Fetching AMD...\n",
      "‚úÖ Loaded 180 bars for AMD (attempt 1)\n",
      "\n",
      "üîÑ Fetching SPY...\n",
      "‚úÖ Loaded 180 bars for SPY (attempt 1)\n",
      "\n",
      "üîÑ Fetching QQQ...\n",
      "‚úÖ Loaded 180 bars for QQQ (attempt 1)\n",
      "\n",
      "======== Backfill summary ========\n",
      "Successful tickers: ['AAPL', 'AMD', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'QQQ', 'SPY', 'TSLA']\n",
      "Failed tickers: []\n"
     ]
    }
   ],
   "source": [
    "DAYS_HISTORY = 180  # how many calendar days to request from Polygon\n",
    "\n",
    "all_rows = []\n",
    "failed = []\n",
    "\n",
    "for symbol in tickers:  # type: ignore\n",
    "    print(f\"\\nüîÑ Fetching {symbol}...\")\n",
    "    \n",
    "    for attempt in range(3):   # up to 3 attempts per symbol\n",
    "        try:\n",
    "            bars = get_underlying_bars(symbol, days=DAYS_HISTORY)  # type: ignore\n",
    "\n",
    "            # If API returns nothing, don't keep retrying\n",
    "            if bars is None or bars.empty:\n",
    "                print(f\"‚ö†Ô∏è No bars for {symbol} (empty response)\")\n",
    "                break\n",
    "\n",
    "            # Tag ticker and store\n",
    "            bars = bars.copy()\n",
    "            bars[\"ticker\"] = symbol\n",
    "            all_rows.append(bars)\n",
    "\n",
    "            print(f\"‚úÖ Loaded {len(bars)} bars for {symbol} (attempt {attempt + 1})\")\n",
    "            break  # success ‚Üí stop retrying this symbol\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed for {symbol}: {e}\")\n",
    "            time.sleep(2 * (attempt + 1))  # simple backoff: 2s, 4s, 6s\n",
    "\n",
    "    else:\n",
    "        # Only hits if all 3 attempts failed\n",
    "        print(f\"üö´ Giving up on {symbol} after 3 failed attempts\")\n",
    "        failed.append(symbol)\n",
    "\n",
    "    # Small pause between symbols to be nice to Polygon / your network\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"\\n======== Backfill summary ========\")\n",
    "if all_rows:\n",
    "    print(\"Successful tickers:\", sorted({df_['ticker'].iloc[0] for df_ in all_rows}))\n",
    "else:\n",
    "    print(\"No successful tickers!\")\n",
    "\n",
    "print(\"Failed tickers:\", failed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bc664",
   "metadata": {},
   "source": [
    "## 4. Combine and clean the raw bar data\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Concatenates all per-ticker DataFrames into a single `df_bars`.\n",
    "- Converts Polygon `timestamp` to a clean `date` column.\n",
    "- Shows a preview of the data.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Having all tickers in one DataFrame makes it easy to write to DuckDB.\n",
    "- A clean `date` column is essential for:\n",
    "  - Grouping by day\n",
    "  - Computing returns\n",
    "  - Aligning features and RL transitions\n",
    "- This is the **canonical raw table** for downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed43f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfill bars columns: ['open', 'high', 'low', 'close', 'volume', 'ticker']\n",
      "Backfill bars index name: timestamp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>214.16</td>\n",
       "      <td>215.1500</td>\n",
       "      <td>211.49</td>\n",
       "      <td>212.69</td>\n",
       "      <td>42432426.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>214.22</td>\n",
       "      <td>218.7600</td>\n",
       "      <td>213.75</td>\n",
       "      <td>215.24</td>\n",
       "      <td>54385391.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-20</td>\n",
       "      <td>213.99</td>\n",
       "      <td>217.4899</td>\n",
       "      <td>212.22</td>\n",
       "      <td>214.10</td>\n",
       "      <td>48862947.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>211.56</td>\n",
       "      <td>218.8400</td>\n",
       "      <td>211.28</td>\n",
       "      <td>218.27</td>\n",
       "      <td>94127768.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-24</td>\n",
       "      <td>221.00</td>\n",
       "      <td>221.4800</td>\n",
       "      <td>218.58</td>\n",
       "      <td>220.73</td>\n",
       "      <td>44299483.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open      high     low   close      volume ticker\n",
       "0  2025-03-18  214.16  215.1500  211.49  212.69  42432426.0   AAPL\n",
       "1  2025-03-19  214.22  218.7600  213.75  215.24  54385391.0   AAPL\n",
       "2  2025-03-20  213.99  217.4899  212.22  214.10  48862947.0   AAPL\n",
       "3  2025-03-21  211.56  218.8400  211.28  218.27  94127768.0   AAPL\n",
       "4  2025-03-24  221.00  221.4800  218.58  220.73  44299483.0   AAPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine and clean the raw bar data\n",
    "\n",
    "# What this cell does\n",
    "# - Concatenate all per-ticker DataFrames into a single df_bars\n",
    "# - Move Polygon‚Äôs time field (index or column) into a proper 'date' column\n",
    "# - Normalize to calendar dates (YYYY-MM-DD)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No data returned from Polygon. Check API key or rate limits.\")\n",
    "\n",
    "# 1) Combine all tickers' bars into one DataFrame WITHOUT dropping the index\n",
    "df_bars = pd.concat(all_rows)\n",
    "\n",
    "print(\"Backfill bars columns:\", list(df_bars.columns))\n",
    "print(\"Backfill bars index name:\", df_bars.index.name)\n",
    "\n",
    "cols = df_bars.columns\n",
    "\n",
    "# 2) Ensure we have a 'date' column from whatever time field Polygon gave us\n",
    "if df_bars.index.name in (\"timestamp\", \"t\"):\n",
    "    # Time is stored in the index (common with Polygon)\n",
    "    df_bars = df_bars.reset_index()\n",
    "    time_col = df_bars.columns[0]          # former index column\n",
    "    df_bars.rename(columns={time_col: \"date\"}, inplace=True)\n",
    "elif \"timestamp\" in cols:\n",
    "    df_bars[\"date\"] = df_bars[\"timestamp\"]\n",
    "elif \"t\" in cols:\n",
    "    df_bars[\"date\"] = df_bars[\"t\"]\n",
    "elif \"date\" in cols:\n",
    "    # Already have a date-like column; reuse it\n",
    "    df_bars[\"date\"] = df_bars[\"date\"]\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        f\"Expected a time column or index in bars, but got columns={list(cols)}, index={df_bars.index.name}\"\n",
    "    )\n",
    "\n",
    "# 3) Convert to proper datetime, then to calendar date\n",
    "df_bars[\"date\"] = pd.to_datetime(df_bars[\"date\"], unit=\"ms\", errors=\"coerce\")\n",
    "if df_bars[\"date\"].isna().all():\n",
    "    # Fallback if it's already datetime and unit=\"ms\" was wrong\n",
    "    df_bars[\"date\"] = pd.to_datetime(df_bars[\"date\"], errors=\"coerce\")\n",
    "\n",
    "if df_bars[\"date\"].isna().all():\n",
    "    raise RuntimeError(\"Failed to convert time field to datetime; inspect df_bars.head().\")\n",
    "\n",
    "df_bars[\"date\"] = df_bars[\"date\"].dt.date\n",
    "\n",
    "df_bars.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b389651",
   "metadata": {},
   "source": [
    "## 5. Compute 20-day and 60-day realized volatility per ticker\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- For each ticker, sorts the bars by date.\n",
    "- Uses `compute_realized_vol()` to estimate:\n",
    "  - 20-day realized volatility (RV20)\n",
    "  - 60-day realized volatility (RV60)\n",
    "- Stores one row per ticker in a `df_rv` snapshot table.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Volatility is the heart of this project:\n",
    "  - It feeds our **Edge Score**.\n",
    "  - It defines **volatility regimes**.\n",
    "  - It shapes the **RL state and reward**.\n",
    "- Having a per-ticker RV snapshot is useful for:\n",
    "  - Feature sanity checks\n",
    "  - Comparisons across names\n",
    "  - UI metrics (e.g., ‚ÄúAvg RV20 across universe‚Äù)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3b739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_rv shape: (1200, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>last_price</th>\n",
       "      <th>day_pct</th>\n",
       "      <th>volume</th>\n",
       "      <th>rv_20d</th>\n",
       "      <th>rv_60d</th>\n",
       "      <th>edge_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>199.20</td>\n",
       "      <td>0.211289</td>\n",
       "      <td>43904635.0</td>\n",
       "      <td>20.597902</td>\n",
       "      <td>51.247261</td>\n",
       "      <td>1.025779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>196.45</td>\n",
       "      <td>-1.380522</td>\n",
       "      <td>51447349.0</td>\n",
       "      <td>20.945016</td>\n",
       "      <td>51.249474</td>\n",
       "      <td>6.591172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>198.42</td>\n",
       "      <td>1.002800</td>\n",
       "      <td>43020691.0</td>\n",
       "      <td>21.483382</td>\n",
       "      <td>51.291068</td>\n",
       "      <td>4.667793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>195.64</td>\n",
       "      <td>-1.401068</td>\n",
       "      <td>38856152.0</td>\n",
       "      <td>21.620035</td>\n",
       "      <td>51.185641</td>\n",
       "      <td>6.480417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>196.58</td>\n",
       "      <td>0.480474</td>\n",
       "      <td>45394689.0</td>\n",
       "      <td>21.672431</td>\n",
       "      <td>51.134823</td>\n",
       "      <td>2.216984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run_date ticker  last_price   day_pct      volume     rv_20d     rv_60d  \\\n",
       "60  2025-06-12   AAPL      199.20  0.211289  43904635.0  20.597902  51.247261   \n",
       "61  2025-06-13   AAPL      196.45 -1.380522  51447349.0  20.945016  51.249474   \n",
       "62  2025-06-16   AAPL      198.42  1.002800  43020691.0  21.483382  51.291068   \n",
       "63  2025-06-17   AAPL      195.64 -1.401068  38856152.0  21.620035  51.185641   \n",
       "64  2025-06-18   AAPL      196.58  0.480474  45394689.0  21.672431  51.134823   \n",
       "\n",
       "    edge_score  \n",
       "60    1.025779  \n",
       "61    6.591172  \n",
       "62    4.667793  \n",
       "63    6.480417  \n",
       "64    2.216984  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Build daily realized vol + edge score from 180-day bars ===\n",
    "\n",
    "# df_bars should already exist from the Polygon backfill:\n",
    "# columns like: ['date', 'ticker', 'open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "bars = df_bars.copy()\n",
    "bars = bars.sort_values([\"ticker\", \"date\"])\n",
    "\n",
    "# 1-day returns\n",
    "bars[\"ret\"] = bars.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "\n",
    "# Daily % move (this is what Notebook 1 calls day_pct)\n",
    "bars[\"day_pct\"] = bars[\"ret\"] * 100.0\n",
    "\n",
    "ann_factor = np.sqrt(252)\n",
    "\n",
    "# 20-day realized vol (annualized, in %)\n",
    "bars[\"rv_20d\"] = (\n",
    "    bars.groupby(\"ticker\")[\"ret\"]\n",
    "        .rolling(20)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "        * ann_factor * 100.0\n",
    ")\n",
    "\n",
    "# 60-day realized vol (annualized, in %)\n",
    "bars[\"rv_60d\"] = (\n",
    "    bars.groupby(\"ticker\")[\"ret\"]\n",
    "        .rolling(60)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "        * ann_factor * 100.0\n",
    ")\n",
    "\n",
    "# Simple ‚Äúedge‚Äù proxy: how big today‚Äôs move is vs recent vol\n",
    "bars[\"edge_score\"] = (bars[\"day_pct\"].abs() / bars[\"rv_20d\"]) * 100.0\n",
    "\n",
    "# This is the table we‚Äôll persist\n",
    "df_rv = (\n",
    "    bars[[\"date\", \"ticker\", \"close\", \"day_pct\", \"volume\",\n",
    "          \"rv_20d\", \"rv_60d\", \"edge_score\"]]\n",
    "      .rename(columns={\"date\": \"run_date\", \"close\": \"last_price\"})\n",
    "      .dropna()\n",
    ")\n",
    "\n",
    "print(\"df_rv shape:\", df_rv.shape)\n",
    "df_rv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d350d",
   "metadata": {},
   "source": [
    "## 6. Write OHLC and volatility tables to DuckDB\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Creates `ohlc_bars` table (if it doesn't exist) matching `df_bars` schema.\n",
    "- Clears any old rows from `ohlc_bars` and inserts the new data.\n",
    "- Creates `daily_rv` table (if it doesn't exist) matching `df_rv`.\n",
    "- Clears and refills `daily_rv`.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- DuckDB now holds our **canonical raw tables**:\n",
    "  - `ohlc_bars` = price and volume history\n",
    "  - `daily_rv` = per-ticker vol snapshot\n",
    "- All other notebooks (01‚Äì06) can reliably read from the same DB.\n",
    "- This looks like a real quant data warehouse pattern, not ad-hoc CSV dumping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6225ba41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohlc_bars row count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows\n",
       "0    1800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_rv row count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows\n",
       "0    1200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screener_snapshots summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows  n_tickers   min_date   max_date\n",
       "0    1200         10 2025-06-12 2025-12-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Persist bars & realized-vol tables into DuckDB ===\n",
    "\n",
    "# 0) Safety: drop old versions so schemas can't conflict\n",
    "con.execute(\"DROP TABLE IF EXISTS ohlc_bars;\")\n",
    "con.execute(\"DROP TABLE IF EXISTS daily_rv;\")\n",
    "con.execute(\"DROP TABLE IF EXISTS screener_snapshots;\")\n",
    "\n",
    "# 1) OHLC bars (180 days √ó 10 tickers = 1800 rows)\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE ohlc_bars AS\n",
    "SELECT * FROM df_bars;\n",
    "\"\"\")\n",
    "\n",
    "print(\"ohlc_bars row count:\")\n",
    "display(con.execute(\"SELECT COUNT(*) AS n_rows FROM ohlc_bars;\").df())\n",
    "\n",
    "# 2) Daily realized vol + edge (df_rv from the cell above)\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE daily_rv AS\n",
    "SELECT * FROM df_rv;\n",
    "\"\"\")\n",
    "\n",
    "print(\"daily_rv row count:\")\n",
    "display(con.execute(\"SELECT COUNT(*) AS n_rows FROM daily_rv;\").df())\n",
    "\n",
    "# 3) Rebuild screener_snapshots using the expected column names\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE screener_snapshots AS\n",
    "SELECT\n",
    "    run_date,\n",
    "    ticker,\n",
    "    last_price,\n",
    "    day_pct,\n",
    "    volume,\n",
    "    rv_20d,\n",
    "    rv_60d,\n",
    "    edge_score\n",
    "FROM daily_rv\n",
    "ORDER BY run_date, ticker;\n",
    "\"\"\")\n",
    "\n",
    "print(\"screener_snapshots summary:\")\n",
    "display(con.execute(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*)               AS n_rows,\n",
    "        COUNT(DISTINCT ticker) AS n_tickers,\n",
    "        MIN(run_date)          AS min_date,\n",
    "        MAX(run_date)          AS max_date\n",
    "    FROM screener_snapshots;\n",
    "\"\"\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d7de71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows\n",
       "0    1200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT COUNT(*) AS n_rows FROM daily_rv\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5b3100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_tickers</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows  n_tickers   min_date   max_date\n",
       "0    1200         10 2025-06-12 2025-12-02"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild screener_snapshots from the full daily_rv history\n",
    "\n",
    "# 1. Drop old table (with just 2 days) if it exists\n",
    "con.execute(\"DROP TABLE IF EXISTS screener_snapshots\")\n",
    "\n",
    "# 2. Recreate screener_snapshots from daily_rv\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE screener_snapshots AS\n",
    "    SELECT\n",
    "        run_date,\n",
    "        ticker,\n",
    "        last_price,\n",
    "        day_pct,\n",
    "        volume,\n",
    "        rv_20d,\n",
    "        rv_60d,\n",
    "        edge_score\n",
    "    FROM daily_rv\n",
    "    ORDER BY run_date, ticker\n",
    "\"\"\")\n",
    "\n",
    "# 3. Sanity check: should now show 1800 rows and 180-day span\n",
    "con.sql(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*)             AS n_rows,\n",
    "        COUNT(DISTINCT ticker) AS n_tickers,\n",
    "        MIN(run_date)        AS min_date,\n",
    "        MAX(run_date)        AS max_date\n",
    "    FROM screener_snapshots\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2d93a",
   "metadata": {},
   "source": [
    "## 7. Quick sanity checks\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Checks the date range stored in `ohlc_bars`.\n",
    "- Counts the number of rows per ticker.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Confirms we **actually** have ~60‚Äì90 days of data.\n",
    "- Confirms that all tickers are present and non-empty.\n",
    "- If something looks off here, we know to fix the data before touching RL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31499d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>2025-12-02</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_date   max_date  n_rows\n",
       "0 2025-03-18 2025-12-02    1800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT \n",
    "    MIN(date) AS min_date,\n",
    "    MAX(date) AS max_date,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM ohlc_bars;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c14bb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMD</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>META</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPY</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  n_rows\n",
       "0   AAPL     180\n",
       "1    AMD     180\n",
       "2   AMZN     180\n",
       "3  GOOGL     180\n",
       "4   META     180\n",
       "5   MSFT     180\n",
       "6   NVDA     180\n",
       "7    QQQ     180\n",
       "8    SPY     180\n",
       "9   TSLA     180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT \n",
    "    ticker,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM ohlc_bars\n",
    "GROUP BY ticker\n",
    "ORDER BY ticker;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c27c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfill bars columns: ['date', 'open', 'high', 'low', 'close', 'volume', 'ticker']\n",
      "Backfill bars index name: None\n",
      "Tickers in backfill: ['AAPL', 'AMD', 'AMZN', 'GOOGL', 'META', 'MSFT', 'NVDA', 'QQQ', 'SPY', 'TSLA']\n",
      "Date range in backfill: 2025-03-18 ‚Üí 2025-12-02\n",
      "Total rows: 1800\n"
     ]
    }
   ],
   "source": [
    "print(\"Backfill bars columns:\", list(df_bars.columns))\n",
    "print(\"Backfill bars index name:\", df_bars.index.name)\n",
    "print(\"Tickers in backfill:\", sorted(df_bars[\"ticker\"].unique()))\n",
    "print(\"Date range in backfill:\", df_bars[\"date\"].min(), \"‚Üí\", df_bars[\"date\"].max())\n",
    "print(\"Total rows:\", len(df_bars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672d5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b22b72",
   "metadata": {},
   "source": [
    "## 8. Wrap-up: what this notebook proves\n",
    "\n",
    "**What we did**\n",
    "\n",
    "- Pulled ~60‚Äì90 days of OHLC data from Polygon for a small ticker universe.\n",
    "- Computed simple realized volatility summaries (RV20, RV60).\n",
    "- Stored everything in DuckDB tables:\n",
    "  - `ohlc_bars`\n",
    "  - `daily_rv`\n",
    "\n",
    "**Why it matters for VAE and RL**\n",
    "\n",
    "- All downstream notebooks (01‚Äì06) and the RL engine now run on **real history**.\n",
    "- This enables:\n",
    "  - More honest EDA and signal analysis\n",
    "  - Realistic regime detection\n",
    "  - RL training on multi-day episodes instead of toy examples\n",
    "\n",
    "**Why it matters**\n",
    "\n",
    "- Shows you can:\n",
    "  - Ingest external market data APIs\n",
    "  - Design a small but solid data model\n",
    "  - Use DuckDB for analytics\n",
    "  - Build a reproducible research pipeline\n",
    "\n",
    "Next step:  \n",
    "Run notebooks **01 ‚Üí 06** so the entire VAE pipeline uses this history.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
