{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee1c599",
   "metadata": {},
   "source": [
    "# Notebook 00 — Historical Backfill Engine (Polygon → DuckDB)\n",
    "\n",
    "This notebook builds a **real historical dataset** for the Volatility Alpha Engine (VAE).\n",
    "\n",
    "We pull 60–90 days of market data from **Polygon**, compute basic volatility stats,\n",
    "and store everything in **DuckDB**. The other notebooks (01–06) and the RL system\n",
    "will read from this same DuckDB file.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Makes our project look like real quant research (not toy, single-day data).\n",
    "- Gives us enough history for EDA, features, regimes, and RL training.\n",
    "- Shows we can build a reproducible data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b6cf3",
   "metadata": {},
   "source": [
    "## 1. Imports and DuckDB connection\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Imports Python libraries we need (dates, dataframes, DuckDB).\n",
    "- Imports our Polygon helper functions from `src/polygon_client.py`.\n",
    "- Connects to the main DuckDB database file for VAE.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- DuckDB is our **single source of truth** for all notebooks.\n",
    "- Using one DB file keeps the pipeline clean and reproducible.\n",
    "- We see a real data-engineering pattern, not ad-hoc CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2caf3742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DB: /home/btheard/projects/volatility-alpha-engine/data/volatility_alpha.duckdb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# --- Make sure we can import from the project root ---\n",
    "PROJECT_ROOT = Path.cwd().parent  # notebooks/ -> project root\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Now this import will work\n",
    "from src.polygon_client import get_underlying_bars, compute_realized_vol\n",
    "\n",
    "# --- Use the SAME DuckDB file as notebooks 1–6 ---\n",
    "DB_PATH = (PROJECT_ROOT / \"data\" / \"volatility_alpha.duckdb\").as_posix()\n",
    "con = duckdb.connect(DB_PATH)\n",
    "\n",
    "print(\"Using DB:\", DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9aefa6",
   "metadata": {},
   "source": [
    "## 2. Choose tickers and backfill window\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Defines the small universe of tickers we care about right now.\n",
    "- Sets a date window (last ~90 calendar days) to backfill.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- ~90 calendar days ≈ 60 trading days, which is enough for:\n",
    "  - 20-day and 60-day realized volatility\n",
    "  - Stable features and RL training episodes\n",
    "- We keep the universe small at first to avoid hitting Polygon rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a032e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2025-09-04', '2025-12-03', ['SPY', 'QQQ', 'TSLA', 'NVDA', 'AMD'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\"SPY\", \"QQQ\", \"TSLA\", \"NVDA\", \"AMD\"]\n",
    "\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)\n",
    "\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "start_date_str, end_date_str, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42e2a2",
   "metadata": {},
   "source": [
    "## 3. Download daily OHLC bars from Polygon\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Loops over each ticker.\n",
    "- Calls `get_underlying_bars()` to fetch roughly 90 days of daily bars.\n",
    "- Attaches a `ticker` column and collects all rows in a list.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- OHLC (Open, High, Low, Close, Volume) is the core price data\n",
    "  used in most trading and RL systems.\n",
    "- This is our **raw market tape** that everything else builds on\n",
    "  (features, regimes, signals, RL environment).\n",
    "- We print basic status so we can see which tickers succeeded or failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948ee42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 90 bars for SPY\n",
      "✓ Loaded 90 bars for QQQ\n",
      "✓ Loaded 90 bars for TSLA\n",
      "✓ Loaded 90 bars for NVDA\n",
      "✓ Loaded 90 bars for AMD\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "\n",
    "for symbol in tickers:\n",
    "    try:\n",
    "        bars = get_underlying_bars(symbol, days=90)\n",
    "        if bars is None or bars.empty:\n",
    "            print(f\"⚠ No bars for {symbol}\")\n",
    "            continue\n",
    "\n",
    "        bars = bars.copy()\n",
    "        bars[\"ticker\"] = symbol\n",
    "        all_rows.append(bars)\n",
    "\n",
    "        print(f\"✓ Loaded {len(bars)} bars for {symbol}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading {symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bc664",
   "metadata": {},
   "source": [
    "## 4. Combine and clean the raw bar data\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Concatenates all per-ticker DataFrames into a single `df_bars`.\n",
    "- Converts Polygon `timestamp` to a clean `date` column.\n",
    "- Shows a preview of the data.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Having all tickers in one DataFrame makes it easy to write to DuckDB.\n",
    "- A clean `date` column is essential for:\n",
    "  - Grouping by day\n",
    "  - Computing returns\n",
    "  - Aligning features and RL transitions\n",
    "- This is the **canonical raw table** for downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed43f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backfill bars columns: ['open', 'high', 'low', 'close', 'volume', 'ticker']\n",
      "Backfill bars index name: timestamp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-28</td>\n",
       "      <td>637.480</td>\n",
       "      <td>638.04</td>\n",
       "      <td>635.540</td>\n",
       "      <td>636.94</td>\n",
       "      <td>54917102.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>638.350</td>\n",
       "      <td>638.67</td>\n",
       "      <td>634.335</td>\n",
       "      <td>635.26</td>\n",
       "      <td>60556278.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-30</td>\n",
       "      <td>635.920</td>\n",
       "      <td>637.68</td>\n",
       "      <td>631.540</td>\n",
       "      <td>634.46</td>\n",
       "      <td>80418851.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>639.455</td>\n",
       "      <td>639.85</td>\n",
       "      <td>630.765</td>\n",
       "      <td>632.08</td>\n",
       "      <td>103385246.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>626.300</td>\n",
       "      <td>626.34</td>\n",
       "      <td>619.290</td>\n",
       "      <td>621.72</td>\n",
       "      <td>140103572.0</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open    high      low   close       volume ticker\n",
       "0  2025-07-28  637.480  638.04  635.540  636.94   54917102.0    SPY\n",
       "1  2025-07-29  638.350  638.67  634.335  635.26   60556278.0    SPY\n",
       "2  2025-07-30  635.920  637.68  631.540  634.46   80418851.0    SPY\n",
       "3  2025-07-31  639.455  639.85  630.765  632.08  103385246.0    SPY\n",
       "4  2025-08-01  626.300  626.34  619.290  621.72  140103572.0    SPY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine and clean the raw bar data\n",
    "\n",
    "# What this cell does\n",
    "# - Concatenate all per-ticker DataFrames into a single df_bars\n",
    "# - Move Polygon’s time field (index or column) into a proper 'date' column\n",
    "# - Normalize to calendar dates (YYYY-MM-DD)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No data returned from Polygon. Check API key or rate limits.\")\n",
    "\n",
    "# 1) Combine all tickers' bars into one DataFrame WITHOUT dropping the index\n",
    "df_bars = pd.concat(all_rows)\n",
    "\n",
    "print(\"Backfill bars columns:\", list(df_bars.columns))\n",
    "print(\"Backfill bars index name:\", df_bars.index.name)\n",
    "\n",
    "cols = df_bars.columns\n",
    "\n",
    "# 2) Ensure we have a 'date' column from whatever time field Polygon gave us\n",
    "if df_bars.index.name in (\"timestamp\", \"t\"):\n",
    "    # Time is stored in the index (common with Polygon)\n",
    "    df_bars = df_bars.reset_index()\n",
    "    time_col = df_bars.columns[0]          # former index column\n",
    "    df_bars.rename(columns={time_col: \"date\"}, inplace=True)\n",
    "elif \"timestamp\" in cols:\n",
    "    df_bars[\"date\"] = df_bars[\"timestamp\"]\n",
    "elif \"t\" in cols:\n",
    "    df_bars[\"date\"] = df_bars[\"t\"]\n",
    "elif \"date\" in cols:\n",
    "    # Already have a date-like column; reuse it\n",
    "    df_bars[\"date\"] = df_bars[\"date\"]\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        f\"Expected a time column or index in bars, but got columns={list(cols)}, index={df_bars.index.name}\"\n",
    "    )\n",
    "\n",
    "# 3) Convert to proper datetime, then to calendar date\n",
    "df_bars[\"date\"] = pd.to_datetime(df_bars[\"date\"], unit=\"ms\", errors=\"coerce\")\n",
    "if df_bars[\"date\"].isna().all():\n",
    "    # Fallback if it's already datetime and unit=\"ms\" was wrong\n",
    "    df_bars[\"date\"] = pd.to_datetime(df_bars[\"date\"], errors=\"coerce\")\n",
    "\n",
    "if df_bars[\"date\"].isna().all():\n",
    "    raise RuntimeError(\"Failed to convert time field to datetime; inspect df_bars.head().\")\n",
    "\n",
    "df_bars[\"date\"] = df_bars[\"date\"].dt.date\n",
    "\n",
    "df_bars.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b389651",
   "metadata": {},
   "source": [
    "## 5. Compute 20-day and 60-day realized volatility per ticker\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- For each ticker, sorts the bars by date.\n",
    "- Uses `compute_realized_vol()` to estimate:\n",
    "  - 20-day realized volatility (RV20)\n",
    "  - 60-day realized volatility (RV60)\n",
    "- Stores one row per ticker in a `df_rv` snapshot table.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Volatility is the heart of this project:\n",
    "  - It feeds our **Edge Score**.\n",
    "  - It defines **volatility regimes**.\n",
    "  - It shapes the **RL state and reward**.\n",
    "- Having a per-ticker RV snapshot is useful for:\n",
    "  - Feature sanity checks\n",
    "  - Comparisons across names\n",
    "  - UI metrics (e.g., “Avg RV20 across universe”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3b739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>rv20</th>\n",
       "      <th>rv60</th>\n",
       "      <th>as_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td>15.045246</td>\n",
       "      <td>12.448073</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>21.560850</td>\n",
       "      <td>17.365192</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>50.368334</td>\n",
       "      <td>50.858019</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>41.892757</td>\n",
       "      <td>37.772929</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>68.514826</td>\n",
       "      <td>73.059756</td>\n",
       "      <td>2025-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       rv20       rv60       as_of\n",
       "0    SPY  15.045246  12.448073  2025-12-02\n",
       "1    QQQ  21.560850  17.365192  2025-12-02\n",
       "2   TSLA  50.368334  50.858019  2025-12-02\n",
       "3   NVDA  41.892757  37.772929  2025-12-02\n",
       "4    AMD  68.514826  73.059756  2025-12-02"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv_rows = []\n",
    "\n",
    "for symbol in tickers:\n",
    "    sub = df_bars[df_bars[\"ticker\"] == symbol].sort_values(\"date\")\n",
    "\n",
    "    if sub.empty:\n",
    "        print(f\"⚠ No data for {symbol}, skipping RV calc.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        rv20 = compute_realized_vol(sub, window=20)\n",
    "        rv60 = compute_realized_vol(sub, window=60)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ RV calc failed for {symbol}: {e}\")\n",
    "        rv20, rv60 = float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    rv_rows.append(\n",
    "        {\n",
    "            \"ticker\": symbol,\n",
    "            \"rv20\": rv20,\n",
    "            \"rv60\": rv60,\n",
    "            \"as_of\": max(sub[\"date\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_rv = pd.DataFrame(rv_rows)\n",
    "df_rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054d350d",
   "metadata": {},
   "source": [
    "## 6. Write OHLC and volatility tables to DuckDB\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Creates `ohlc_bars` table (if it doesn't exist) matching `df_bars` schema.\n",
    "- Clears any old rows from `ohlc_bars` and inserts the new data.\n",
    "- Creates `daily_rv` table (if it doesn't exist) matching `df_rv`.\n",
    "- Clears and refills `daily_rv`.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- DuckDB now holds our **canonical raw tables**:\n",
    "  - `ohlc_bars` = price and volume history\n",
    "  - `daily_rv` = per-ticker vol snapshot\n",
    "- All other notebooks (01–06) can reliably read from the same DB.\n",
    "- This looks like a real quant data warehouse pattern, not ad-hoc CSV dumping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6225ba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_rows\n",
       "0     450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create / replace ohlc_bars\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS ohlc_bars AS\n",
    "SELECT * FROM df_bars LIMIT 0;\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"DELETE FROM ohlc_bars;\")\n",
    "con.execute(\"INSERT INTO ohlc_bars SELECT * FROM df_bars;\")\n",
    "\n",
    "# Create / replace daily_rv\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_rv AS\n",
    "SELECT * FROM df_rv LIMIT 0;\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"DELETE FROM daily_rv;\")\n",
    "con.execute(\"INSERT INTO daily_rv SELECT * FROM df_rv;\")\n",
    "\n",
    "con.execute(\"SELECT COUNT(*) AS n_rows FROM ohlc_bars;\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2d93a",
   "metadata": {},
   "source": [
    "## 7. Quick sanity checks\n",
    "\n",
    "**What this cell does**\n",
    "\n",
    "- Checks the date range stored in `ohlc_bars`.\n",
    "- Counts the number of rows per ticker.\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Confirms we **actually** have ~60–90 days of data.\n",
    "- Confirms that all tickers are present and non-empty.\n",
    "- If something looks off here, we know to fix the data before touching RL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31499d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-28</td>\n",
       "      <td>2025-12-02</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_date   max_date  n_rows\n",
       "0 2025-07-28 2025-12-02     450"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT \n",
    "    MIN(date) AS min_date,\n",
    "    MAX(date) AS max_date,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM ohlc_bars;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c14bb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPY</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  n_rows\n",
       "0    AMD      90\n",
       "1   NVDA      90\n",
       "2    QQQ      90\n",
       "3    SPY      90\n",
       "4   TSLA      90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"\"\"\n",
    "SELECT \n",
    "    ticker,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM ohlc_bars\n",
    "GROUP BY ticker\n",
    "ORDER BY ticker;\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b22b72",
   "metadata": {},
   "source": [
    "## 8. Wrap-up: what this notebook proves\n",
    "\n",
    "**What we did**\n",
    "\n",
    "- Pulled ~60–90 days of OHLC data from Polygon for a small ticker universe.\n",
    "- Computed simple realized volatility summaries (RV20, RV60).\n",
    "- Stored everything in DuckDB tables:\n",
    "  - `ohlc_bars`\n",
    "  - `daily_rv`\n",
    "\n",
    "**Why it matters for VAE and RL**\n",
    "\n",
    "- All downstream notebooks (01–06) and the RL engine now run on **real history**.\n",
    "- This enables:\n",
    "  - More honest EDA and signal analysis\n",
    "  - Realistic regime detection\n",
    "  - RL training on multi-day episodes instead of toy examples\n",
    "\n",
    "**Why it matters**\n",
    "\n",
    "- Shows you can:\n",
    "  - Ingest external market data APIs\n",
    "  - Design a small but solid data model\n",
    "  - Use DuckDB for analytics\n",
    "  - Build a reproducible research pipeline\n",
    "\n",
    "Next step:  \n",
    "Run notebooks **01 → 06** so the entire VAE pipeline uses this history.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
